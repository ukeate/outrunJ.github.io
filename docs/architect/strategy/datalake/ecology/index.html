<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  Hadoop体系
  #

发行版
    Apache Hadoop
    CDH(Cloudera&#39;s Distribution Including Apache Hadoop)
    HDP(Hortonworks Data Platform)
    宜信
        D.Bus
            # 数据收集与计算
        UAVStack
            # AIOps, 智能运维
            UAV.Monitor
                # 监控
            UAV.APM
                # 性能管理
            UAV.ServiceGovern
                # 服务治理
            UAV.MSCP
                # 微服务计算
        Wormhole
            # SPaaS(Stream Processing as a Service)
        Gartner
            # ITOA，算法即运维
大数据 
    PB级数据
    4V
        volume(大量)
        velocity(高速)
        variety(多样)
        value(低价值密度)
    场景
        物流仓储: 精细化运营，命中率
        推荐
        保险: 风险预测
        金融: 用户特征
        房产: 精准投策、营销
        AI
    组织部门
        平台: 集群
            Hadoop、Flume、Kafka、HBase、Spark等搭建
            性能监控、调优
        数据仓库: 写SQL
            ETL, 数据清洗
            Hive, 数据分析、建模
        数据挖掘
            数据支持
            算法、推荐、用户画像
        报表
            JavaEE
hadoop
    Apache开源, 分布式系统基础架构
    面临问题
        硬盘
            1块: 10TB-14TB 
            1PB: 102块硬盘
        算
            MySQL5.5: 300w-500w
            MySQL8: 1亿、1GB
    Doug Cutting
        GFS -&gt; HDFS
            存储
        Map-Reduce -&gt; MapReduce
            计算
        BigTable -&gt; HBase
            表式存储
    发展
        2003-2004: Google公开部分GFS和MapReduce
        2005: Hadoop成为Apache Lucene子项目Nutch了一部分
        2006.3: MapReduce和NDFS(Nutch Distributed File System)纳入Hadoop
    发行版本
        Apache: 开源
        Cloudera: Doug Cutting, 一键部署, 资源占用大
        Hortonworks: 雅虎工程师，贡献Hadoop 80%代码, 一键部署
        阿里云
    特点
        高可靠性：多副本
        高扩展性
        高效性: 并行运行
        高容错性
    组成
        Hadoop1.x
            HDFS(存), MapReduce(算、资源调度), Common
        Hadoop2.x
            HDFS(存), MapReduce(算), Yarn(资源调度), Common
        Hadoop3.x


  HDFS
  #

# Hadoop Distributed File System, 一开始为Nutch搜索引擎开发
存储模型
	按字节切割,block存储,block多副本
	不支持修改(因为修改文件而非block, 且会引发规模修改)，可以追加
主从架构
	NameNode
		树形目录
		内存存储元数据，可持久化(EditLog事务日志, FsImage)
			NameNode启动时安全模式
				SecondaryNameNode合并EditLog到新FsImage
				DataNode上报block列表
		存副本策略
	DataNode
		本地文件形式存block, 存校验
		与NameNode心跳，汇报block列表
	Client
		交互元数据和block
API结构
	推荐节点数不过5000
	角色：一个进程
Block副本放置策略
	Pipeline
HA
	JournalNode
		NameNode同步EditLog
	FailoverController
		利用ZooKeeper
		同主机下监控NameNode
		验证对方主机主NN是否真的挂掉，调用对方降级为Standby
问题及方案
    单点故障
        多NameNode，主备(2.x只能1主1备, 3.x可以1主5备)
    压力大，内存受限
        联帮: Federation(元数据分片)
配置网络
    /etc/sysconfig/network-scripts/ifcfg-eth0
    /etc/sysconfig/network
        NETWORKING=YES
        HOSTNAME=node01    
    /etc/hosts
    /etc/selinux/config
        SELINUX=disabled
    /etc/ntp.conf
        server htp1.aliyun.com
    /etc/profile
        export JAVA_HOME=/usr/java/default
        export PATH=$PATH:$JAVA_HOME/bin
    service iptables stop &amp; chkconfig iptables off
    service ntp start &amp; chkconfig ntp on
    配ssh免密登录
部署配置
    mkdir /opt/bigdata
    /etc/profile
        export HADOOP_HOME=/opt/bigdata/hadoop-2.6.5
        export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    /etc/hadoop
        hadoop-env.sh
            export JAVA_HOME=/usr/java/default
        core-site.xml
            &lt;name&gt;fs.defaultFS&lt;/name&gt;
            &lt;value&gt;hdfs://node01:9000&lt;/value&gt;
        hdfs-site.xml
            &lt;name&gt;fs.replication&lt;/name&gt;
            &lt;value&gt;1&lt;/value&gt;
            &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
            &lt;value&gt;/var/bigdata/hadoop/local/dfs/name&lt;/value&gt;
                # namenode元数据
            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
            &lt;value&gt;/var/bigdata/hadoop/local/dfs/data&lt;/value&gt;
            &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
            &lt;value&gt;node01:50090&lt;/value&gt;
            &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;
            &lt;value&gt;/var/bigdata/hadoop/local/dfs/secondary&lt;/value&gt;
        slaves
            node1
命令
    hdfs namenode -format
    start-dfs.sh
    访问页面 node01:50070 node01:50090
    hdfs dfs -mkdir -p /user/root
    hdfs dfs -D dfs.blocksize=1048576 -put a.txt /user/root


  使用
  #

软件结构
    0        jdk, Hadoop                        NameNode, DFSZKFailoverController
    1        jdk, Hadoop                        NameNode, DFSZKFailoverController
    2        jdk, Hadoop                        ResourceManager
    3        jdk, Hadoop, Zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
    4        jdk, Hadoop, Zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
    5        jdk, Hadoop, Zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
Zookeeper
    配置conf/zoo.cfg
        tickTime=2000                        # 心跳间隔(ms)
        initLimit=10                        # 初始化时最多容忍心跳次数
        syncLimit=5                        # 同步失败最多容忍心跳次数
        dataDir=/usr/local/Zookeeper/data        # 运行时文件目录
        clientPort=2181                # 运行端口号
        server.1=主机名或ip:2888:3888        # 服务运行端口与选举端口
        server.2=主机名或ip:2888:3888
        server.3=主机名或ip:2888:3888
    命令
        ./bin/zkServer.sh start
        ./bin/zkServer.sh status
        jps                                        # 显示名为QuorumPeerMain
Hadoop
    Hadoop-env.sh
        export JAVA_HOME=
    core-site.xml
        &lt;configuration&gt;
            &lt;property&gt;
                &lt;name&gt;fs.defaultFS&lt;/name&gt;
                &lt;value&gt;HDFS://ns1&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;Hadoop.tmp.dir&lt;/name&gt;
                &lt;value&gt;/usr/local/Hadoop-2.2.0/tmp&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;ha.Zookeeper.quorum&lt;/name&gt;
                &lt;value&gt;192.168.56.13:2181, 192.168.56.14:2181, 192.168.56.15:2181&lt;/value&gt;
            &lt;/property&gt;
        &lt;/configuration&gt;
    HDFS-site.xml
        &lt;property&gt;
            &lt;name&gt;dfs.nameservices&lt;/name&gt;
            &lt;value&gt;ns1&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;
            &lt;value&gt;nn1,nn2&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;
            &lt;value&gt;192.168.56.10:9000&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;
            &lt;value&gt;192.168.56.10:50070&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;
            &lt;value&gt;192.168.56.11:9000&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;
            &lt;value&gt;192.168.56.11:50070&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
            &lt;value&gt;qjournal://192.168.56.13:8485;192.168.56.14:8485;192.168.56.15:8485&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
            &lt;value&gt;/usr/local/Hadoop-2.2.0/journal&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
            &lt;value&gt;true&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;
            &lt;value&gt;org.Apache.Hadoop.HDFS.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
            &lt;value&gt;sshfence&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
            &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;
        &lt;/property&gt;
    mapred-site.xml
        &lt;property&gt;
            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
            &lt;value&gt;Yarn&lt;/value&gt;
        &lt;/property&gt;
    Yarn-site.xml
        &lt;property&gt;
            &lt;name&gt;Yarn.resourcemanager.hostname&lt;/name&gt;
            &lt;value&gt;192.168.56.12&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;Yarn.nodemanager.aux-services&lt;/name&gt;
            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
        &lt;/property&gt;
    etc/Hadoop/slaves
        192.168.56.13
        192.168.56.14
        192.168.56.15
收尾
    ssh免登录(0到1,2,3,4,5)
        ssh-keygen -t rsa
        ssh-copy-id -i 192.168.56.11            # 这样就可以免登录访问192.168.56.11了
                                                ## ssh-copy-id -i localhost 免登录自己
    复制Hadoop2.2.0(从0到1,2,3,4,5)
    添加Hadoop_home到环境变量
        etc/profile
            export HADOOP_HOME=/usr/local/Hadoop-2.2.0
            export PATH=$PATH:$HADOOP_HOME/bin
启动
    0 上启动
        ./sbin/Hadoop-daemons.sh start journalnode
    0 上格式化namenode
        Hadoop namenode -format


  HBase
  #

介绍
	Hadoop Database, 实时分布式, bigtable列簇数据库, 非结构化，自动切分, 并发读写
	只能row key查询, master有单点问题
版本
	0.98
	1.x
	2.x
原理
	修改只追加记录，合并时删除
架构
	Client
		提供接口，维护客户端缓存
	Zookeeper
		只有一个活跃master
		存Region寻址入口
		实时监控region server在线信息，通知master
		存schema、table元数据
	Master
		为region server分配region	
		region server负载均衡
		失效region server重新分配region
		管理table CRUD
	RegionServer
		维护region
		切分大region
	Region
		表水平分region分配在多个region server, region增大时裂变
	HLog
		写Store之前先写HLog, flush到HDFS, store写完后HDFS存储移到old，2天后删除	
	Store
		region由多个store组成, 一个store对应一个CF
		store先写入memstore, 到阈值后启动flashcache写入storefile
		storefile增长到阈值，进行合并
			minor compaction
			major compaction，默认最多256M
		region所有storefile达到阈值，region分割


  Spark
  #

介绍
	in memory, 准实时的批处理，生态好于Storm
	无事务
集群
	Master
	Worker
	Driver
	Executor	
组件
	Spark RDD(Resiliennt Distributed Datasets)
	Spark Core 批计算，取代MR
		粗粒度资源申请，task自行分配启动快，executor不kill
		内存计算
		chain
	Spark Streamming 流计算，取代Storm
		批计算无限缩小，实时性差
		默认无状态
			用updateStateByKey保存上次计算结果，变成有状态
			借助Redis或ES存
	Spark SQL 数据处理
	Spark MlLib 机器学习
	Spark R 数据分析
使用
	val session = SparkSessionBase.createSparkSession()
	var sc = session.sparkContext
	var rdd = sc.makeRDD(List(1,2,3,4,5,6))
	val mapRDD = rdd.map(x -&gt; {
		x
	})
	val filterRDD = mapRDD.filter(x =&gt; {
		true
	})
	filterRDD.count


  独立体系
  #


  Flink
  #

特点
	高吞吐、低延迟、高性能
	支持事件时间(Event Time)
	擅长有状态的计算	
		内存
		磁盘
		RocksDB
	灵活的窗口（Window）操作： time, count, session
	基于轻量级分布式快照（CheckPoint）实现容错，保证exactly-once
	基于JVM实现独立内存管理
	Save Points方便代码升级
批计算是流计算的特例
	unbound streams		# 定义开始不定义结束，流计算
	bounded streams		# 定义开始也定义结束，批计算
迟到数据问题
	温度窗口
	水位线(Watermark)
集群
	JobManager(JVM进程)
	TaskManager(JVM进程)
		Task Slot	
			一组固定的资源，隔离内存，不隔离核
			一般与核数对应，核支持超线程时一个算两个
配置
	/etc
		/flink-conf.yaml
		/slaves
		/masters
组件
	部署
		Single JVM		# 多线程模拟
		Standalone
		YARN	
	库
		CEP				# 复杂事件库
		Table
		FlinkML
		Gelly
使用
	import org.apache.flink.streaming.api.scala._

	val env = StreamExecutionEnvironment.getExecutionEnvironment
	val initStream:DataStream[String] = env.socketTextStream(&quot;node01&quot;, 8888)
	val wordStream = initStream.flatMap(_.split(&quot; &quot;))
	val pairStream = wordStream.map((_, 1))
	val keyByStream = pairStream.keyBy(0)
	val restStream = keyByStream.sum(1)
	restStream.print()
	env.execute(&quot;job1&quot;)
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://runout.run/docs/architect/strategy/datalake/ecology/">
  <meta property="og:site_name" content="outrun的笔记">
  <meta property="og:title" content="outrun的笔记">
  <meta property="og:description" content="Hadoop体系 # 发行版 Apache Hadoop CDH(Cloudera&#39;s Distribution Including Apache Hadoop) HDP(Hortonworks Data Platform) 宜信 D.Bus # 数据收集与计算 UAVStack # AIOps, 智能运维 UAV.Monitor # 监控 UAV.APM # 性能管理 UAV.ServiceGovern # 服务治理 UAV.MSCP # 微服务计算 Wormhole # SPaaS(Stream Processing as a Service) Gartner # ITOA，算法即运维 大数据 PB级数据 4V volume(大量) velocity(高速) variety(多样) value(低价值密度) 场景 物流仓储: 精细化运营，命中率 推荐 保险: 风险预测 金融: 用户特征 房产: 精准投策、营销 AI 组织部门 平台: 集群 Hadoop、Flume、Kafka、HBase、Spark等搭建 性能监控、调优 数据仓库: 写SQL ETL, 数据清洗 Hive, 数据分析、建模 数据挖掘 数据支持 算法、推荐、用户画像 报表 JavaEE hadoop Apache开源, 分布式系统基础架构 面临问题 硬盘 1块: 10TB-14TB 1PB: 102块硬盘 算 MySQL5.5: 300w-500w MySQL8: 1亿、1GB Doug Cutting GFS -&gt; HDFS 存储 Map-Reduce -&gt; MapReduce 计算 BigTable -&gt; HBase 表式存储 发展 2003-2004: Google公开部分GFS和MapReduce 2005: Hadoop成为Apache Lucene子项目Nutch了一部分 2006.3: MapReduce和NDFS(Nutch Distributed File System)纳入Hadoop 发行版本 Apache: 开源 Cloudera: Doug Cutting, 一键部署, 资源占用大 Hortonworks: 雅虎工程师，贡献Hadoop 80%代码, 一键部署 阿里云 特点 高可靠性：多副本 高扩展性 高效性: 并行运行 高容错性 组成 Hadoop1.x HDFS(存), MapReduce(算、资源调度), Common Hadoop2.x HDFS(存), MapReduce(算), Yarn(资源调度), Common Hadoop3.x HDFS # # Hadoop Distributed File System, 一开始为Nutch搜索引擎开发 存储模型 按字节切割,block存储,block多副本 不支持修改(因为修改文件而非block, 且会引发规模修改)，可以追加 主从架构 NameNode 树形目录 内存存储元数据，可持久化(EditLog事务日志, FsImage) NameNode启动时安全模式 SecondaryNameNode合并EditLog到新FsImage DataNode上报block列表 存副本策略 DataNode 本地文件形式存block, 存校验 与NameNode心跳，汇报block列表 Client 交互元数据和block API结构 推荐节点数不过5000 角色：一个进程 Block副本放置策略 Pipeline HA JournalNode NameNode同步EditLog FailoverController 利用ZooKeeper 同主机下监控NameNode 验证对方主机主NN是否真的挂掉，调用对方降级为Standby 问题及方案 单点故障 多NameNode，主备(2.x只能1主1备, 3.x可以1主5备) 压力大，内存受限 联帮: Federation(元数据分片) 配置网络 /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network NETWORKING=YES HOSTNAME=node01 /etc/hosts /etc/selinux/config SELINUX=disabled /etc/ntp.conf server htp1.aliyun.com /etc/profile export JAVA_HOME=/usr/java/default export PATH=$PATH:$JAVA_HOME/bin service iptables stop &amp; chkconfig iptables off service ntp start &amp; chkconfig ntp on 配ssh免密登录 部署配置 mkdir /opt/bigdata /etc/profile export HADOOP_HOME=/opt/bigdata/hadoop-2.6.5 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin /etc/hadoop hadoop-env.sh export JAVA_HOME=/usr/java/default core-site.xml &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://node01:9000&lt;/value&gt; hdfs-site.xml &lt;name&gt;fs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/var/bigdata/hadoop/local/dfs/name&lt;/value&gt; # namenode元数据 &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/var/bigdata/hadoop/local/dfs/data&lt;/value&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node01:50090&lt;/value&gt; &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt; &lt;value&gt;/var/bigdata/hadoop/local/dfs/secondary&lt;/value&gt; slaves node1 命令 hdfs namenode -format start-dfs.sh 访问页面 node01:50070 node01:50090 hdfs dfs -mkdir -p /user/root hdfs dfs -D dfs.blocksize=1048576 -put a.txt /user/root 使用 # 软件结构 0 jdk, Hadoop NameNode, DFSZKFailoverController 1 jdk, Hadoop NameNode, DFSZKFailoverController 2 jdk, Hadoop ResourceManager 3 jdk, Hadoop, Zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain 4 jdk, Hadoop, Zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain 5 jdk, Hadoop, Zookeeper DataNode, NodeManager, JournalNode, QuorumPeerMain Zookeeper 配置conf/zoo.cfg tickTime=2000 # 心跳间隔(ms) initLimit=10 # 初始化时最多容忍心跳次数 syncLimit=5 # 同步失败最多容忍心跳次数 dataDir=/usr/local/Zookeeper/data # 运行时文件目录 clientPort=2181 # 运行端口号 server.1=主机名或ip:2888:3888 # 服务运行端口与选举端口 server.2=主机名或ip:2888:3888 server.3=主机名或ip:2888:3888 命令 ./bin/zkServer.sh start ./bin/zkServer.sh status jps # 显示名为QuorumPeerMain Hadoop Hadoop-env.sh export JAVA_HOME= core-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;HDFS://ns1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;Hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/Hadoop-2.2.0/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.Zookeeper.quorum&lt;/name&gt; &lt;value&gt;192.168.56.13:2181, 192.168.56.14:2181, 192.168.56.15:2181&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; HDFS-site.xml &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt; &lt;value&gt;192.168.56.10:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt; &lt;value&gt;192.168.56.10:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt; &lt;value&gt;192.168.56.11:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt; &lt;value&gt;192.168.56.11:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://192.168.56.13:8485;192.168.56.14:8485;192.168.56.15:8485&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/usr/local/Hadoop-2.2.0/journal&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt; &lt;value&gt;org.Apache.Hadoop.HDFS.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; mapred-site.xml &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;Yarn&lt;/value&gt; &lt;/property&gt; Yarn-site.xml &lt;property&gt; &lt;name&gt;Yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;192.168.56.12&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;Yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; etc/Hadoop/slaves 192.168.56.13 192.168.56.14 192.168.56.15 收尾 ssh免登录(0到1,2,3,4,5) ssh-keygen -t rsa ssh-copy-id -i 192.168.56.11 # 这样就可以免登录访问192.168.56.11了 ## ssh-copy-id -i localhost 免登录自己 复制Hadoop2.2.0(从0到1,2,3,4,5) 添加Hadoop_home到环境变量 etc/profile export HADOOP_HOME=/usr/local/Hadoop-2.2.0 export PATH=$PATH:$HADOOP_HOME/bin 启动 0 上启动 ./sbin/Hadoop-daemons.sh start journalnode 0 上格式化namenode Hadoop namenode -format HBase # 介绍 Hadoop Database, 实时分布式, bigtable列簇数据库, 非结构化，自动切分, 并发读写 只能row key查询, master有单点问题 版本 0.98 1.x 2.x 原理 修改只追加记录，合并时删除 架构 Client 提供接口，维护客户端缓存 Zookeeper 只有一个活跃master 存Region寻址入口 实时监控region server在线信息，通知master 存schema、table元数据 Master 为region server分配region	region server负载均衡 失效region server重新分配region 管理table CRUD RegionServer 维护region 切分大region Region 表水平分region分配在多个region server, region增大时裂变 HLog 写Store之前先写HLog, flush到HDFS, store写完后HDFS存储移到old，2天后删除	Store region由多个store组成, 一个store对应一个CF store先写入memstore, 到阈值后启动flashcache写入storefile storefile增长到阈值，进行合并 minor compaction major compaction，默认最多256M region所有storefile达到阈值，region分割 Spark # 介绍 in memory, 准实时的批处理，生态好于Storm 无事务 集群 Master Worker Driver Executor	组件 Spark RDD(Resiliennt Distributed Datasets) Spark Core 批计算，取代MR 粗粒度资源申请，task自行分配启动快，executor不kill 内存计算 chain Spark Streamming 流计算，取代Storm 批计算无限缩小，实时性差 默认无状态 用updateStateByKey保存上次计算结果，变成有状态 借助Redis或ES存 Spark SQL 数据处理 Spark MlLib 机器学习 Spark R 数据分析 使用 val session = SparkSessionBase.createSparkSession() var sc = session.sparkContext var rdd = sc.makeRDD(List(1,2,3,4,5,6)) val mapRDD = rdd.map(x -&gt; { x }) val filterRDD = mapRDD.filter(x =&gt; { true }) filterRDD.count 独立体系 # Flink # 特点 高吞吐、低延迟、高性能 支持事件时间(Event Time) 擅长有状态的计算	内存 磁盘 RocksDB 灵活的窗口（Window）操作： time, count, session 基于轻量级分布式快照（CheckPoint）实现容错，保证exactly-once 基于JVM实现独立内存管理 Save Points方便代码升级 批计算是流计算的特例 unbound streams	# 定义开始不定义结束，流计算 bounded streams	# 定义开始也定义结束，批计算 迟到数据问题 温度窗口 水位线(Watermark) 集群 JobManager(JVM进程) TaskManager(JVM进程) Task Slot	一组固定的资源，隔离内存，不隔离核 一般与核数对应，核支持超线程时一个算两个 配置 /etc /flink-conf.yaml /slaves /masters 组件 部署 Single JVM	# 多线程模拟 Standalone YARN	库 CEP	# 复杂事件库 Table FlinkML Gelly 使用 import org.apache.flink.streaming.api.scala._ val env = StreamExecutionEnvironment.getExecutionEnvironment val initStream:DataStream[String] = env.socketTextStream(&#34;node01&#34;, 8888) val wordStream = initStream.flatMap(_.split(&#34; &#34;)) val pairStream = wordStream.map((_, 1)) val keyByStream = pairStream.keyBy(0) val restStream = keyByStream.sum(1) restStream.print() env.execute(&#34;job1&#34;)">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">
    <meta property="article:modified_time" content="2022-11-14T20:22:20+08:00">
<title>Ecology | outrun的笔记</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://runout.run/docs/architect/strategy/datalake/ecology/">
<link rel="stylesheet" href="/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.de073bde8a6e6d0bd83cd24901f31edc4f18d2b60264b1a5c09063bb3745c1c7.js" integrity="sha256-3gc73opubQvYPNJJAfMe3E8Y0rYCZLGlwJBjuzdFwcc=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  <script data-ad-client="ca-pub-6239994681364905" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<meta name="baidu_union_verify" content="aacbc30462cce84b2333063d99284e3b">
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><img src="/logo.png" alt="Logo" class="book-icon" /><span>outrun的笔记</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>















  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/" class="">架构</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/code/" class="">代码</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/code/security/" class="">Security</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/code/design_mode/" class="">Java设计模式</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/project/" class="">工程设计</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/project/ddd/" class="">工程</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/project/frontend/" class="">前端</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>战略性技术</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/ai/" class="">AI</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/ai/map/" class="">知识图谱</a>
  

        </li>
      
    
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/iot/" class="">IoT</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/iot/framework/" class="">Framework</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/meta/" class="">IoT</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/meta/media/" class="">媒体</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/middle_platform/" class="">中台</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/block_chain/" class="">Block Chain</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>Cloud</span>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/datalake/" class="">Datalake</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/datalake/ecology/" class="active">Ecology</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/strategy/edge/" class="">Edge</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/manage/" class="">Manage</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/manage/organize/" class="">组织</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/manage/organize/people/" class="">人员</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/method/" class="">Method</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/method/product_plan/" class="">产品规划</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/method/code_plan/" class="">代码规划</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/method/ops_plan/" class="">运维规划</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/method/advice_plan/" class="">咨询规划</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/method/architect/" class="">服务治理</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/method/project_plan/" class="">项目规划</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/method/test_plan/" class="">测试规划</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/architect/summary/" class="">这些年我做过的技术</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/db/" class="">数据库</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/db/mongodb/" class="">Mongodb</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/db/postgresql/" class="">Postgre SQL</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/db/elasticsearch/" class="">Elasticsearch</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/db/mysql/" class="">Mysql</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/db/oracle/" class="">Oracle</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/db/redis/" class="">Redis</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/" class="">中间件</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/distributed/" class="">支撑-分布式</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/distributed/spring_cloud/" class="">Spring Cloud</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/library_frontend/" class="">前端</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/library_frontend/bootstrap/" class="">Bootstrap</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/library_frontend/threejs/" class="">Threejs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/library_frontend/angular/" class="">Angular</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/library_frontend/jquery/" class="">Jquery</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/library_frontend/react/" class="">React</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/library/" class="">小功能</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/library/hibernate/" class="">Hibernate</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <span>Container</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/container/nginx/" class="">Nginx</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/middleware/container/nodejs/" class="">Nodejs</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/" class="">程序语言</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/principle/" class="">程序语言原理</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/haskell/" class="">Haskell</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/elixir/" class="">Elixir</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/go/" class="">Go</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/python/" class="">Python</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/clojure/" class="">Clojure</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/js/" class="">JS</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/java/" class="">Java</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/java/java_reactive/" class="">Java响应式编程</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/java/javaweb/" class="">JavaWeb</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/java/juc/" class="">Java并发</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/java/jvm/" class="">JVM</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/java/collection/" class="">Collection</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/java/spring/" class="">Spring</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/markup_language/" class="">Markup Language</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/markup_language/html/" class="">Html</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/pl/markup_language/css/" class="">Css</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/" class="">工具</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/ops/" class="">运维</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/ops/monitor/" class="">Monitor</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/ops/docker/" class="">Docker</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/ops/k8s/" class="">Kubernetes</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/product/enterprise_system/" class="">企业级系统</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/develop/" class="">Develop</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/develop/eclipse/" class="">Eclipse</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/develop/vim/" class="">VIM</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/develop/apple/" class="">Apple</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/develop/jetbrains/" class="">Jetbrains</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/linux/" class="">Linux</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/linux/linux_program/" class="">LinuxProgram</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/linux/scene/" class="">LinuxScene</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/linux/linux_tool/" class="">LinuxTool</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/product/framework/" class="">Framework</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/physics/" class="">实物工具</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/test/" class="">测试</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/tool/test/debug/" class="">程序调试</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/cache/" class="">Cache</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/cache/ops/" class="">Ops</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/cache/work_code/" class="">Work Code</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/cache/template/" class="">模板配置</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/cache/soft_arch/" class="">软考架构师</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/misc/" class="">杂项</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/" class="">基本功</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/speach/" class="">演说</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/body/" class="">身体</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/computer/" class="">Computer</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/computer/principle/" class="">支撑-原理</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/computer/performance/" class="">Performance</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/algorithm/" class="">算法</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/algorithm/thought/" class="">算法思想</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/algorithm/data_structure/" class="">数据结构</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/basic/algorithm/math/" class="">数学</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>














</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Ecology</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#hadoop体系">Hadoop体系</a>
      <ul>
        <li><a href="#hdfs">HDFS</a></li>
        <li><a href="#使用">使用</a></li>
        <li><a href="#hbase">HBase</a></li>
        <li><a href="#spark">Spark</a></li>
      </ul>
    </li>
    <li><a href="#独立体系">独立体系</a>
      <ul>
        <li><a href="#flink">Flink</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="hadoop体系">
  Hadoop体系
  <a class="anchor" href="#hadoop%e4%bd%93%e7%b3%bb">#</a>
</h1>
<pre><code>发行版
    Apache Hadoop
    CDH(Cloudera's Distribution Including Apache Hadoop)
    HDP(Hortonworks Data Platform)
    宜信
        D.Bus
            # 数据收集与计算
        UAVStack
            # AIOps, 智能运维
            UAV.Monitor
                # 监控
            UAV.APM
                # 性能管理
            UAV.ServiceGovern
                # 服务治理
            UAV.MSCP
                # 微服务计算
        Wormhole
            # SPaaS(Stream Processing as a Service)
        Gartner
            # ITOA，算法即运维
大数据 
    PB级数据
    4V
        volume(大量)
        velocity(高速)
        variety(多样)
        value(低价值密度)
    场景
        物流仓储: 精细化运营，命中率
        推荐
        保险: 风险预测
        金融: 用户特征
        房产: 精准投策、营销
        AI
    组织部门
        平台: 集群
            Hadoop、Flume、Kafka、HBase、Spark等搭建
            性能监控、调优
        数据仓库: 写SQL
            ETL, 数据清洗
            Hive, 数据分析、建模
        数据挖掘
            数据支持
            算法、推荐、用户画像
        报表
            JavaEE
hadoop
    Apache开源, 分布式系统基础架构
    面临问题
        硬盘
            1块: 10TB-14TB 
            1PB: 102块硬盘
        算
            MySQL5.5: 300w-500w
            MySQL8: 1亿、1GB
    Doug Cutting
        GFS -&gt; HDFS
            存储
        Map-Reduce -&gt; MapReduce
            计算
        BigTable -&gt; HBase
            表式存储
    发展
        2003-2004: Google公开部分GFS和MapReduce
        2005: Hadoop成为Apache Lucene子项目Nutch了一部分
        2006.3: MapReduce和NDFS(Nutch Distributed File System)纳入Hadoop
    发行版本
        Apache: 开源
        Cloudera: Doug Cutting, 一键部署, 资源占用大
        Hortonworks: 雅虎工程师，贡献Hadoop 80%代码, 一键部署
        阿里云
    特点
        高可靠性：多副本
        高扩展性
        高效性: 并行运行
        高容错性
    组成
        Hadoop1.x
            HDFS(存), MapReduce(算、资源调度), Common
        Hadoop2.x
            HDFS(存), MapReduce(算), Yarn(资源调度), Common
        Hadoop3.x
</code></pre>
<h2 id="hdfs">
  HDFS
  <a class="anchor" href="#hdfs">#</a>
</h2>
<pre><code># Hadoop Distributed File System, 一开始为Nutch搜索引擎开发
存储模型
	按字节切割,block存储,block多副本
	不支持修改(因为修改文件而非block, 且会引发规模修改)，可以追加
主从架构
	NameNode
		树形目录
		内存存储元数据，可持久化(EditLog事务日志, FsImage)
			NameNode启动时安全模式
				SecondaryNameNode合并EditLog到新FsImage
				DataNode上报block列表
		存副本策略
	DataNode
		本地文件形式存block, 存校验
		与NameNode心跳，汇报block列表
	Client
		交互元数据和block
API结构
	推荐节点数不过5000
	角色：一个进程
Block副本放置策略
	Pipeline
HA
	JournalNode
		NameNode同步EditLog
	FailoverController
		利用ZooKeeper
		同主机下监控NameNode
		验证对方主机主NN是否真的挂掉，调用对方降级为Standby
问题及方案
    单点故障
        多NameNode，主备(2.x只能1主1备, 3.x可以1主5备)
    压力大，内存受限
        联帮: Federation(元数据分片)
配置网络
    /etc/sysconfig/network-scripts/ifcfg-eth0
    /etc/sysconfig/network
        NETWORKING=YES
        HOSTNAME=node01    
    /etc/hosts
    /etc/selinux/config
        SELINUX=disabled
    /etc/ntp.conf
        server htp1.aliyun.com
    /etc/profile
        export JAVA_HOME=/usr/java/default
        export PATH=$PATH:$JAVA_HOME/bin
    service iptables stop &amp; chkconfig iptables off
    service ntp start &amp; chkconfig ntp on
    配ssh免密登录
部署配置
    mkdir /opt/bigdata
    /etc/profile
        export HADOOP_HOME=/opt/bigdata/hadoop-2.6.5
        export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    /etc/hadoop
        hadoop-env.sh
            export JAVA_HOME=/usr/java/default
        core-site.xml
            &lt;name&gt;fs.defaultFS&lt;/name&gt;
            &lt;value&gt;hdfs://node01:9000&lt;/value&gt;
        hdfs-site.xml
            &lt;name&gt;fs.replication&lt;/name&gt;
            &lt;value&gt;1&lt;/value&gt;
            &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
            &lt;value&gt;/var/bigdata/hadoop/local/dfs/name&lt;/value&gt;
                # namenode元数据
            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
            &lt;value&gt;/var/bigdata/hadoop/local/dfs/data&lt;/value&gt;
            &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
            &lt;value&gt;node01:50090&lt;/value&gt;
            &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;
            &lt;value&gt;/var/bigdata/hadoop/local/dfs/secondary&lt;/value&gt;
        slaves
            node1
命令
    hdfs namenode -format
    start-dfs.sh
    访问页面 node01:50070 node01:50090
    hdfs dfs -mkdir -p /user/root
    hdfs dfs -D dfs.blocksize=1048576 -put a.txt /user/root
</code></pre>
<h2 id="使用">
  使用
  <a class="anchor" href="#%e4%bd%bf%e7%94%a8">#</a>
</h2>
<pre><code>软件结构
    0        jdk, Hadoop                        NameNode, DFSZKFailoverController
    1        jdk, Hadoop                        NameNode, DFSZKFailoverController
    2        jdk, Hadoop                        ResourceManager
    3        jdk, Hadoop, Zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
    4        jdk, Hadoop, Zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
    5        jdk, Hadoop, Zookeeper        DataNode, NodeManager, JournalNode, QuorumPeerMain
Zookeeper
    配置conf/zoo.cfg
        tickTime=2000                        # 心跳间隔(ms)
        initLimit=10                        # 初始化时最多容忍心跳次数
        syncLimit=5                        # 同步失败最多容忍心跳次数
        dataDir=/usr/local/Zookeeper/data        # 运行时文件目录
        clientPort=2181                # 运行端口号
        server.1=主机名或ip:2888:3888        # 服务运行端口与选举端口
        server.2=主机名或ip:2888:3888
        server.3=主机名或ip:2888:3888
    命令
        ./bin/zkServer.sh start
        ./bin/zkServer.sh status
        jps                                        # 显示名为QuorumPeerMain
Hadoop
    Hadoop-env.sh
        export JAVA_HOME=
    core-site.xml
        &lt;configuration&gt;
            &lt;property&gt;
                &lt;name&gt;fs.defaultFS&lt;/name&gt;
                &lt;value&gt;HDFS://ns1&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;Hadoop.tmp.dir&lt;/name&gt;
                &lt;value&gt;/usr/local/Hadoop-2.2.0/tmp&lt;/value&gt;
            &lt;/property&gt;
            &lt;property&gt;
                &lt;name&gt;ha.Zookeeper.quorum&lt;/name&gt;
                &lt;value&gt;192.168.56.13:2181, 192.168.56.14:2181, 192.168.56.15:2181&lt;/value&gt;
            &lt;/property&gt;
        &lt;/configuration&gt;
    HDFS-site.xml
        &lt;property&gt;
            &lt;name&gt;dfs.nameservices&lt;/name&gt;
            &lt;value&gt;ns1&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;
            &lt;value&gt;nn1,nn2&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;
            &lt;value&gt;192.168.56.10:9000&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;
            &lt;value&gt;192.168.56.10:50070&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;
            &lt;value&gt;192.168.56.11:9000&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;
            &lt;value&gt;192.168.56.11:50070&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
            &lt;value&gt;qjournal://192.168.56.13:8485;192.168.56.14:8485;192.168.56.15:8485&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
            &lt;value&gt;/usr/local/Hadoop-2.2.0/journal&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
            &lt;value&gt;true&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;
            &lt;value&gt;org.Apache.Hadoop.HDFS.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
            &lt;value&gt;sshfence&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
            &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;
        &lt;/property&gt;
    mapred-site.xml
        &lt;property&gt;
            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
            &lt;value&gt;Yarn&lt;/value&gt;
        &lt;/property&gt;
    Yarn-site.xml
        &lt;property&gt;
            &lt;name&gt;Yarn.resourcemanager.hostname&lt;/name&gt;
            &lt;value&gt;192.168.56.12&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
            &lt;name&gt;Yarn.nodemanager.aux-services&lt;/name&gt;
            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
        &lt;/property&gt;
    etc/Hadoop/slaves
        192.168.56.13
        192.168.56.14
        192.168.56.15
收尾
    ssh免登录(0到1,2,3,4,5)
        ssh-keygen -t rsa
        ssh-copy-id -i 192.168.56.11            # 这样就可以免登录访问192.168.56.11了
                                                ## ssh-copy-id -i localhost 免登录自己
    复制Hadoop2.2.0(从0到1,2,3,4,5)
    添加Hadoop_home到环境变量
        etc/profile
            export HADOOP_HOME=/usr/local/Hadoop-2.2.0
            export PATH=$PATH:$HADOOP_HOME/bin
启动
    0 上启动
        ./sbin/Hadoop-daemons.sh start journalnode
    0 上格式化namenode
        Hadoop namenode -format
</code></pre>
<h2 id="hbase">
  HBase
  <a class="anchor" href="#hbase">#</a>
</h2>
<pre><code>介绍
	Hadoop Database, 实时分布式, bigtable列簇数据库, 非结构化，自动切分, 并发读写
	只能row key查询, master有单点问题
版本
	0.98
	1.x
	2.x
原理
	修改只追加记录，合并时删除
架构
	Client
		提供接口，维护客户端缓存
	Zookeeper
		只有一个活跃master
		存Region寻址入口
		实时监控region server在线信息，通知master
		存schema、table元数据
	Master
		为region server分配region	
		region server负载均衡
		失效region server重新分配region
		管理table CRUD
	RegionServer
		维护region
		切分大region
	Region
		表水平分region分配在多个region server, region增大时裂变
	HLog
		写Store之前先写HLog, flush到HDFS, store写完后HDFS存储移到old，2天后删除	
	Store
		region由多个store组成, 一个store对应一个CF
		store先写入memstore, 到阈值后启动flashcache写入storefile
		storefile增长到阈值，进行合并
			minor compaction
			major compaction，默认最多256M
		region所有storefile达到阈值，region分割
</code></pre>
<h2 id="spark">
  Spark
  <a class="anchor" href="#spark">#</a>
</h2>
<pre><code>介绍
	in memory, 准实时的批处理，生态好于Storm
	无事务
集群
	Master
	Worker
	Driver
	Executor	
组件
	Spark RDD(Resiliennt Distributed Datasets)
	Spark Core 批计算，取代MR
		粗粒度资源申请，task自行分配启动快，executor不kill
		内存计算
		chain
	Spark Streamming 流计算，取代Storm
		批计算无限缩小，实时性差
		默认无状态
			用updateStateByKey保存上次计算结果，变成有状态
			借助Redis或ES存
	Spark SQL 数据处理
	Spark MlLib 机器学习
	Spark R 数据分析
使用
	val session = SparkSessionBase.createSparkSession()
	var sc = session.sparkContext
	var rdd = sc.makeRDD(List(1,2,3,4,5,6))
	val mapRDD = rdd.map(x -&gt; {
		x
	})
	val filterRDD = mapRDD.filter(x =&gt; {
		true
	})
	filterRDD.count
</code></pre>
<h1 id="独立体系">
  独立体系
  <a class="anchor" href="#%e7%8b%ac%e7%ab%8b%e4%bd%93%e7%b3%bb">#</a>
</h1>
<h2 id="flink">
  Flink
  <a class="anchor" href="#flink">#</a>
</h2>
<pre><code>特点
	高吞吐、低延迟、高性能
	支持事件时间(Event Time)
	擅长有状态的计算	
		内存
		磁盘
		RocksDB
	灵活的窗口（Window）操作： time, count, session
	基于轻量级分布式快照（CheckPoint）实现容错，保证exactly-once
	基于JVM实现独立内存管理
	Save Points方便代码升级
批计算是流计算的特例
	unbound streams		# 定义开始不定义结束，流计算
	bounded streams		# 定义开始也定义结束，批计算
迟到数据问题
	温度窗口
	水位线(Watermark)
集群
	JobManager(JVM进程)
	TaskManager(JVM进程)
		Task Slot	
			一组固定的资源，隔离内存，不隔离核
			一般与核数对应，核支持超线程时一个算两个
配置
	/etc
		/flink-conf.yaml
		/slaves
		/masters
组件
	部署
		Single JVM		# 多线程模拟
		Standalone
		YARN	
	库
		CEP				# 复杂事件库
		Table
		FlinkML
		Gelly
使用
	import org.apache.flink.streaming.api.scala._

	val env = StreamExecutionEnvironment.getExecutionEnvironment
	val initStream:DataStream[String] = env.socketTextStream(&quot;node01&quot;, 8888)
	val wordStream = initStream.flatMap(_.split(&quot; &quot;))
	val pairStream = wordStream.map((_, 1))
	val keyByStream = pairStream.keyBy(0)
	val restStream = keyByStream.sum(1)
	restStream.print()
	env.execute(&quot;job1&quot;)
</code></pre>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">


  <div><a class="flex align-center" href="https://github.com/outrunJ/hugo-blog/commit/2f21611cabda6ad61a59703a1951538430601829" title='Last modified by outrun | Nov 14, 2022' target="_blank" rel="noopener">
      <img src="/svg/calendar.svg" class="book-icon" alt="" />
      <span>Nov 14, 2022</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/outrunJ/hugo-blog/tree/master/content/content/docs/architect/strategy/datalake/ecology.md" target="_blank" rel="noopener">
      <img src="/svg/edit.svg" class="book-icon" alt="" />
      <span>Edit this page</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#hadoop体系">Hadoop体系</a>
      <ul>
        <li><a href="#hdfs">HDFS</a></li>
        <li><a href="#使用">使用</a></li>
        <li><a href="#hbase">HBase</a></li>
        <li><a href="#spark">Spark</a></li>
      </ul>
    </li>
    <li><a href="#独立体系">独立体系</a>
      <ul>
        <li><a href="#flink">Flink</a></li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












